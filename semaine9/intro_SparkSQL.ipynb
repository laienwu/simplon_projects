{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9Y6wY6L-bia"
   },
   "source": [
    "## DataFrames et Spark SQL\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T08:16:05.585039Z",
     "iopub.status.busy": "2024-08-23T08:16:05.584040Z",
     "iopub.status.idle": "2024-08-23T08:16:11.376256Z",
     "shell.execute_reply": "2024-08-23T08:16:11.376256Z",
     "shell.execute_reply.started": "2024-08-23T08:16:05.585039Z"
    },
    "executionInfo": {
     "elapsed": 12482,
     "status": "ok",
     "timestamp": 1724328516145,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "uLinsTTV-bic",
    "outputId": "7c85d19e-3fe1-4605-adcf-75fa53645739",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark SQL</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=Spark SQL>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create entry points to spark\n",
    "try:\n",
    "    sc.stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Spark SQL\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqu1W0d2-bie"
   },
   "source": [
    "### Generate your own DataFrame\n",
    "Instead of accessing the file system, let's create a DataFrame by generating the data.  In this case, we'll first create the `stringRDD` RDD and then convert it into a DataFrame when we're reading `stringJSONRDD` using `spark.read.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T08:16:11.376256Z",
     "iopub.status.busy": "2024-08-23T08:16:11.376256Z",
     "iopub.status.idle": "2024-08-23T08:16:11.688152Z",
     "shell.execute_reply": "2024-08-23T08:16:11.688152Z",
     "shell.execute_reply.started": "2024-08-23T08:16:11.376256Z"
    },
    "executionInfo": {
     "elapsed": 399,
     "status": "ok",
     "timestamp": 1724328516533,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "-eU6jpy4-bif"
   },
   "outputs": [],
   "source": [
    "# Generate our own JSON data\n",
    "\n",
    "stringJSONRDD = sc.parallelize((\"\"\"\n",
    "  { \"id\": \"123\",\n",
    "    \"name\": \"Katie\",\n",
    "    \"age\": 19,\n",
    "    \"eyeColor\": \"brown\"\n",
    "  }\"\"\",\n",
    "   \"\"\"{\n",
    "    \"id\": \"234\",\n",
    "    \"name\": \"Michael\",\n",
    "    \"age\": 22,\n",
    "    \"eyeColor\": \"green\"\n",
    "  }\"\"\",\n",
    "  \"\"\"{\n",
    "    \"id\": \"345\",\n",
    "    \"name\": \"Simone\",\n",
    "    \"age\": 23,\n",
    "    \"eyeColor\": \"blue\"\n",
    "  }\"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T08:16:11.692165Z",
     "iopub.status.busy": "2024-08-23T08:16:11.688152Z",
     "iopub.status.idle": "2024-08-23T08:16:30.027923Z",
     "shell.execute_reply": "2024-08-23T08:16:30.026907Z",
     "shell.execute_reply.started": "2024-08-23T08:16:11.688152Z"
    },
    "executionInfo": {
     "elapsed": 14396,
     "status": "ok",
     "timestamp": 1724328530923,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "S1YtrhIR-big"
   },
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "swimmersJSON = spark.read.json(stringJSONRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T08:16:30.029098Z",
     "iopub.status.busy": "2024-08-23T08:16:30.029098Z",
     "iopub.status.idle": "2024-08-23T08:16:30.090389Z",
     "shell.execute_reply": "2024-08-23T08:16:30.090389Z",
     "shell.execute_reply.started": "2024-08-23T08:16:30.029098Z"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1724328530926,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "utOZmEFH-bih",
    "outputId": "7ba8ba9e-0b23-4734-b370-a07fcac45d74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: bigint, eyeColor: string, id: string, name: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swimmersJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T08:16:30.093419Z",
     "iopub.status.busy": "2024-08-23T08:16:30.090389Z",
     "iopub.status.idle": "2024-08-23T08:16:43.293374Z",
     "shell.execute_reply": "2024-08-23T08:16:43.293374Z",
     "shell.execute_reply.started": "2024-08-23T08:16:30.093419Z"
    },
    "executionInfo": {
     "elapsed": 819,
     "status": "ok",
     "timestamp": 1724328531739,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "kUV85mlZ-bij",
    "outputId": "68dcafc3-3896-4c13-f73c-460a527ad14e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+-------+\n",
      "|age|eyeColor| id|   name|\n",
      "+---+--------+---+-------+\n",
      "| 19|   brown|123|  Katie|\n",
      "| 22|   green|234|Michael|\n",
      "| 23|    blue|345| Simone|\n",
      "+---+--------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "swimmersJSON.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICCVUGks-bij"
   },
   "source": [
    "DataFrame.createOrReplaceTempView(name: str) â†’ None\n",
    "\n",
    "Creates or replaces a local temporary view with this DataFrame.\n",
    "\n",
    "=> The lifetime of this temporary table is tied to the SparkSession that was used to create this DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T08:17:34.208608Z",
     "iopub.status.busy": "2024-08-23T08:17:34.207531Z",
     "iopub.status.idle": "2024-08-23T08:17:34.284999Z",
     "shell.execute_reply": "2024-08-23T08:17:34.284999Z",
     "shell.execute_reply.started": "2024-08-23T08:17:34.208608Z"
    },
    "id": "eZ-RbBRY-bik"
   },
   "outputs": [],
   "source": [
    "# Create temporary table\n",
    "\n",
    "swimmersJSON.createOrReplaceTempView(\"swimmersJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T08:17:34.894345Z",
     "iopub.status.busy": "2024-08-23T08:17:34.891944Z",
     "iopub.status.idle": "2024-08-23T08:17:48.043971Z",
     "shell.execute_reply": "2024-08-23T08:17:48.042960Z",
     "shell.execute_reply.started": "2024-08-23T08:17:34.894345Z"
    },
    "id": "s4JKYBGt-bil",
    "outputId": "ca43a6f6-110a-4328-e6da-0b87f4cf48bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+-------+\n",
      "|age|eyeColor| id|   name|\n",
      "+---+--------+---+-------+\n",
      "| 19|   brown|123|  Katie|\n",
      "| 22|   green|234|Michael|\n",
      "| 23|    blue|345| Simone|\n",
      "+---+--------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DataFrame API\n",
    "swimmersJSON.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T08:17:48.046970Z",
     "iopub.status.busy": "2024-08-23T08:17:48.046970Z",
     "iopub.status.idle": "2024-08-23T08:18:00.851416Z",
     "shell.execute_reply": "2024-08-23T08:18:00.849913Z",
     "shell.execute_reply.started": "2024-08-23T08:17:48.046970Z"
    },
    "id": "pwNMku6B-bin",
    "outputId": "1b9ce210-c123-471e-c256-9187665d956a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=19, eyeColor='brown', id='123', name='Katie'),\n",
       " Row(age=22, eyeColor='green', id='234', name='Michael'),\n",
       " Row(age=23, eyeColor='blue', id='345', name='Simone')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SQL Query\n",
    "spark.sql(\"select * from swimmersJSON\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQjncPCo-bio"
   },
   "source": [
    "#### Inferring the Schema Using Reflection\n",
    "Note that Apache Spark is inferring the schema using reflection; i.e. it automaticlaly determines the schema of the data based on reviewing the JSON data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T08:18:00.853429Z",
     "iopub.status.busy": "2024-08-23T08:18:00.852425Z",
     "iopub.status.idle": "2024-08-23T08:18:00.861596Z",
     "shell.execute_reply": "2024-08-23T08:18:00.860396Z",
     "shell.execute_reply.started": "2024-08-23T08:18:00.853429Z"
    },
    "id": "NqnuNN6O-bio",
    "outputId": "035430a6-f216-43b5-8401-53a4f46951cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- eyeColor: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema\n",
    "swimmersJSON.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6PnmylD-bio"
   },
   "source": [
    "Notice that Spark was able to determine infer the schema (when reviewing the schema using `.printSchema`).\n",
    "\n",
    "But what if we want to programmatically specify the schema?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmT-yleS-bip"
   },
   "source": [
    "#### Programmatically Specifying the Schema\n",
    "In this case, let's specify the schema for a `CSV` text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T08:18:00.865060Z",
     "iopub.status.busy": "2024-08-23T08:18:00.863716Z",
     "iopub.status.idle": "2024-08-23T08:18:01.667456Z",
     "shell.execute_reply": "2024-08-23T08:18:01.666451Z",
     "shell.execute_reply.started": "2024-08-23T08:18:00.865060Z"
    },
    "id": "MtUVVuKQ-bip"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "# Generate our own CSV data\n",
    "#   This way we don't have to access the file system yet.\n",
    "stringCSVRDD = sc.parallelize([(123, 'Katie', 19, 'brown'), (234, 'Michael', 22, 'green'), (345, 'Simone', 23, 'blue')])\n",
    "\n",
    "# The schema is encoded in a string, using StructType we define the schema using various pyspark.sql.types\n",
    "schemaString = \"id name age eyeColor\"\n",
    "schema = StructType([\n",
    "    StructField(\"id\", LongType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", LongType(), True),\n",
    "    StructField(\"eyeColor\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Apply the schema to the RDD and Create DataFrame\n",
    "swimmers = spark.createDataFrame(stringCSVRDD, schema)\n",
    "\n",
    "# Creates a temporary view using the DataFrame\n",
    "swimmers.createOrReplaceTempView(\"swimmers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T08:18:01.670952Z",
     "iopub.status.busy": "2024-08-23T08:18:01.669941Z",
     "iopub.status.idle": "2024-08-23T08:18:01.676245Z",
     "shell.execute_reply": "2024-08-23T08:18:01.675238Z",
     "shell.execute_reply.started": "2024-08-23T08:18:01.669941Z"
    },
    "id": "b39-bj7U-bip",
    "outputId": "4cabdc88-5b2a-46f3-b994-ce05767b1fa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- eyeColor: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema\n",
    "#   Notice that we have redefined id as Long (instead of String)\n",
    "swimmers.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T08:18:01.677248Z",
     "iopub.status.busy": "2024-08-23T08:18:01.677248Z",
     "iopub.status.idle": "2024-08-23T08:18:15.626680Z",
     "shell.execute_reply": "2024-08-23T08:18:15.626680Z",
     "shell.execute_reply.started": "2024-08-23T08:18:01.677248Z"
    },
    "id": "3siIkEYv-bip",
    "outputId": "fa5045ff-0677-4b65-81ca-99750a5d1710"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=123, name='Katie', age=19, eyeColor='brown'),\n",
       " Row(id=234, name='Michael', age=22, eyeColor='green'),\n",
       " Row(id=345, name='Simone', age=23, eyeColor='blue')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SQL Query\n",
    "spark.sql(\"select * from swimmers\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBZ6JYeR-biq"
   },
   "source": [
    "As you can see from above, we can programmatically apply the `schema` instead of allowing the Spark engine to infer the schema via reflection.\n",
    "\n",
    "Additional Resources include:\n",
    "* [PySpark API Reference](https://spark.apache.org/docs/2.0.0/api/python/pyspark.sql.html)\n",
    "* [Spark SQL, DataFrames, and Datasets Guide](https://spark.apache.org/docs/latest/sql-programming-guide.html#programmatically-specifying-the-schema): This is in reference to Programmatically Specifying the Schema using a `CSV` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMQW5_SF-biq"
   },
   "source": [
    "#### SparkSession\n",
    "\n",
    "Notice that we're no longer using `sqlContext.read...` but instead `spark.read...`.  This is because as part of Spark 2.0, `HiveContext`, `SQLContext`, `StreamingContext`, `SparkContext` have been merged together into the Spark Session `spark`.\n",
    "* Entry point for reading data\n",
    "* Working with metadata\n",
    "* Configuration\n",
    "* Cluster resource management\n",
    "\n",
    "For more information, please refer to [How to use SparkSession in Apache Spark](https://sparkbyexamples.com/spark/sparksession-explained-with-examples/) ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3lBCHyz-biq"
   },
   "source": [
    "### Querying with the DataFrame API\n",
    "With DataFrames, you can start writing your queries using the DataFrame API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T08:18:15.629557Z",
     "iopub.status.busy": "2024-08-23T08:18:15.628104Z",
     "iopub.status.idle": "2024-08-23T08:18:29.430187Z",
     "shell.execute_reply": "2024-08-23T08:18:29.428672Z",
     "shell.execute_reply.started": "2024-08-23T08:18:15.629557Z"
    },
    "id": "UTG9ZlG6-bir",
    "outputId": "19bb04fc-3d80-48fe-ae1e-c7aa60f57947"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+--------+\n",
      "| id|   name|age|eyeColor|\n",
      "+---+-------+---+--------+\n",
      "|123|  Katie| 19|   brown|\n",
      "|234|Michael| 22|   green|\n",
      "|345| Simone| 23|    blue|\n",
      "+---+-------+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the values\n",
    "swimmers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T08:18:29.431694Z",
     "iopub.status.busy": "2024-08-23T08:18:29.430187Z",
     "iopub.status.idle": "2024-08-23T08:18:29.441478Z",
     "shell.execute_reply": "2024-08-23T08:18:29.440419Z",
     "shell.execute_reply.started": "2024-08-23T08:18:29.431694Z"
    },
    "id": "XqTln9nV-bir",
    "outputId": "5efda65d-1f83-4bd3-d614-25c9e7288e4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, name: string, age: bigint, eyeColor: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using Databricks `display` command to view the data easier\n",
    "display(swimmers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T08:18:29.443022Z",
     "iopub.status.busy": "2024-08-23T08:18:29.441987Z",
     "iopub.status.idle": "2024-08-23T08:18:42.803506Z",
     "shell.execute_reply": "2024-08-23T08:18:42.802324Z",
     "shell.execute_reply.started": "2024-08-23T08:18:29.443022Z"
    },
    "id": "nmZVKTex-bis",
    "outputId": "a301c8f0-4de3-4dea-a417-da8e91ea06d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get count of rows\n",
    "swimmers.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T08:18:42.805019Z",
     "iopub.status.busy": "2024-08-23T08:18:42.805019Z",
     "iopub.status.idle": "2024-08-23T08:18:55.149298Z",
     "shell.execute_reply": "2024-08-23T08:18:55.148286Z",
     "shell.execute_reply.started": "2024-08-23T08:18:42.805019Z"
    },
    "id": "XzA2nQlH-bis",
    "outputId": "52f28fb1-436b-4bac-a8e7-2fdcc8b272d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|age|\n",
      "+---+---+\n",
      "|234| 22|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the id, age where age = 22\n",
    "swimmers.select(\"id\", \"age\").filter(\"age = 22\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T08:18:55.151297Z",
     "iopub.status.busy": "2024-08-23T08:18:55.151297Z",
     "iopub.status.idle": "2024-08-23T08:19:07.911214Z",
     "shell.execute_reply": "2024-08-23T08:19:07.910201Z",
     "shell.execute_reply.started": "2024-08-23T08:18:55.151297Z"
    },
    "id": "Nv3H68Og-bit",
    "outputId": "2e1ff6ef-15ac-4324-d255-64215a816661"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|  name|eyeColor|\n",
      "+------+--------+\n",
      "| Katie|   brown|\n",
      "|Simone|    blue|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the name, eyeColor where eyeColor like 'b%'\n",
    "swimmers.select(\"name\", \"eyeColor\").filter(\"eyeColor like 'b%'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WnI819yT-bit"
   },
   "source": [
    "### Querying with SQL\n",
    "With DataFrames, you can start writing your queries using `Spark SQL` - a SQL dialect that is compatible with the Hive Query Language (or HiveQL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T08:19:07.913306Z",
     "iopub.status.busy": "2024-08-23T08:19:07.912295Z",
     "iopub.status.idle": "2024-08-23T08:19:20.331686Z",
     "shell.execute_reply": "2024-08-23T08:19:20.330792Z",
     "shell.execute_reply.started": "2024-08-23T08:19:07.913306Z"
    },
    "id": "1GBRy83Z-bit",
    "outputId": "0f789f70-d8a5-42e0-a975-807bfa9c9531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+--------+\n",
      "| id|   name|age|eyeColor|\n",
      "+---+-------+---+--------+\n",
      "|123|  Katie| 19|   brown|\n",
      "|234|Michael| 22|   green|\n",
      "|345| Simone| 23|    blue|\n",
      "+---+-------+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute SQL Query and return the data\n",
    "spark.sql(\"select * from swimmers\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMm6SxDu-biu"
   },
   "source": [
    "Let's get the row count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T08:19:20.333222Z",
     "iopub.status.busy": "2024-08-23T08:19:20.332694Z",
     "iopub.status.idle": "2024-08-23T08:19:33.271631Z",
     "shell.execute_reply": "2024-08-23T08:19:33.270620Z",
     "shell.execute_reply.started": "2024-08-23T08:19:20.333222Z"
    },
    "id": "oq2HlFGp-biu",
    "outputId": "351a8896-4ed7-4856-b856-54cf7cf2afc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       3|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get count of rows in SQL\n",
    "spark.sql(\"select count(1) from swimmers\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T08:19:33.276681Z",
     "iopub.status.busy": "2024-08-23T08:19:33.275678Z"
    },
    "id": "g0S6mrWU-biu",
    "outputId": "9493a5ef-cc4e-4195-c292-1af84318d750"
   },
   "outputs": [],
   "source": [
    "# Query id and age for swimmers with age = 22 via DataFrame API\n",
    "swimmers.select(\"id\", \"age\").filter(\"age = 22\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_einkY0e-biv",
    "outputId": "7a76d4a4-0614-4e99-ace3-a4dcdf9d50ed"
   },
   "outputs": [],
   "source": [
    "# Query id and age for swimmers with age = 22 via DataFrame API in another way\n",
    "swimmers.select(swimmers.id, swimmers.age).filter(swimmers.age == 22).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dzyo_pBg-biv",
    "outputId": "5c279e0d-f3d2-45b8-a633-a92e3164019e"
   },
   "outputs": [],
   "source": [
    "# Query id and age for swimmers with age = 22 in SQL\n",
    "spark.sql(\"select id, age from swimmers where age = 22\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1AWBjOLl-biw",
    "outputId": "20974ba4-ae73-4911-dbfe-438693cb0e77"
   },
   "outputs": [],
   "source": [
    "# Query name and eye color for swimmers with eye color starting with the letter 'b'\n",
    "spark.sql(\"select name, eyeColor from swimmers where eyeColor like 'b%'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOMCD5Uy-biw"
   },
   "source": [
    "## Application:\n",
    "\n",
    "Query flight departure delays by State and City by joining the departure delay and join to the airport codes (to identify state and city)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eORCVibK-biw"
   },
   "source": [
    "* On-Time Performance Datasets\n",
    "\n",
    "The source `airports` dataset can be found at [OpenFlights Airport, airline and route data](https://openflights.org/data.php).\n",
    "\n",
    "The `flights`, also known as the `departuredelays`, dataset can be found at [Airline On-Time Performance and Causes of Flight Delays: On_Time Data](https://catalog.data.gov/dataset/airline-on-time-performance-and-causes-of-flight-delays-on-time-data)\n",
    "\n",
    "1- Read into spark DataFrames the datasets departuredelays.csv and airport-codes.txt.\n",
    "\n",
    "2- display dataframe with .show(), .cache() , print the data schema\n",
    "\n",
    "3- Create a local temporary view with these dataframes.\n",
    "\n",
    "4- answer the queries below:\n",
    "\n",
    "* Query Sum of Flight Delays by City and Origin Code (for Washington State)\n",
    "* Query Sum of Flight Delays by State (for the US)\n",
    "* Add 2 more analysis axes of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 1919,
     "status": "ok",
     "timestamp": 1724329650106,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "j1NVlT3N-biw"
   },
   "outputs": [],
   "source": [
    "flightPerf=spark.read.csv(\"departuredelays.csv\",header=True)\n",
    "airports=spark.read.csv(\"airport-codes.txt\", sep='\\t',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 912,
     "status": "ok",
     "timestamp": 1724330002960,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "7GQ80XB1-bix",
    "outputId": "0b0b8866-af05-41b8-cc80-977b0b1f642d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+------+-----------+\n",
      "|    date|delay|distance|origin|destination|\n",
      "+--------+-----+--------+------+-----------+\n",
      "|01011245|    6|     602|   ABE|        ATL|\n",
      "|01020600|   -8|     369|   ABE|        DTW|\n",
      "+--------+-----+--------+------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightPerf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1724330007468,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "2u2rJVFp-bix",
    "outputId": "4509fd44-da5a-4ebb-fd19-bc991f05dea9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-------+----+\n",
      "|      City|State|Country|IATA|\n",
      "+----------+-----+-------+----+\n",
      "|Abbotsford|   BC| Canada| YXX|\n",
      "|  Aberdeen|   SD|    USA| ABR|\n",
      "+----------+-----+-------+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airports.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1724331617790,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "-1BtFGWxIlbe",
    "outputId": "e5f3b5f7-74bf-4371-e77d-e13ed4d44d14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[date: string, delay: string, distance: string, origin: string, destination: string]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flightPerf.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 342,
     "status": "ok",
     "timestamp": 1724331763638,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "_PmXbRIa-biy"
   },
   "outputs": [],
   "source": [
    "flightPerf.createOrReplaceTempView(\"toto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1724331887392,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "7OZmu6eh-biy",
    "outputId": "acb2eb57-af7c-4332-a5e0-261df03f97b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(date='01011245', delay='6', distance='602', origin='ABE', destination='ATL'),\n",
       " Row(date='01020600', delay='-8', distance='369', origin='ABE', destination='DTW')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from toto\").take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BLyhrPgMKN3"
   },
   "source": [
    "\n",
    "    Query Sum of Flight Delays by City and Origin Code (for Washington State)\n",
    "    Query Sum of Flight Delays by State (for the US)\n",
    "    Add 2 more analysis axes of your choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "executionInfo": {
     "elapsed": 373,
     "status": "ok",
     "timestamp": 1724331992301,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "HLjMng78MU76"
   },
   "outputs": [],
   "source": [
    "flightPerf.createOrReplaceTempView('flight')\n",
    "airports.createOrReplaceTempView('airport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1795,
     "status": "ok",
     "timestamp": 1724333529085,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "ITqU5vcuM__S",
    "outputId": "492952bc-4a1c-42b8-a948-0fb6d9903002"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+--------+\n",
      "|         City|origin|  Delays|\n",
      "+-------------+------+--------+\n",
      "|Washington DC|   DCA|137086.0|\n",
      "|Washington DC|   IAD|260151.0|\n",
      "+-------------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query Sum of Flight Delays by City and Origin Code (for Washington State)\n",
    "spark.sql(\"select a.City, f.origin, sum(f.delay) as Delays from flight f join airport a on a.IATA = f.origin where a.City = 'Washington DC' group by a.City, f.origin\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1222,
     "status": "ok",
     "timestamp": 1724334552527,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "DOsHrcNET43M",
    "outputId": "0960ba72-bc58-472a-a46a-e42f55dcf9f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+----------+\n",
      "|         City|origin|sum(delay)|\n",
      "+-------------+------+----------+\n",
      "|Washington DC|   DCA|  137086.0|\n",
      "|Washington DC|   IAD|  260151.0|\n",
      "+-------------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(flightPerf.select('delay', 'origin').join(airports.select('IATA','City'),flightPerf.origin==airports.IATA)\n",
    "                                      .groupby(['City','origin']).agg({'delay':'sum'})\n",
    "                                      .filter(airports.City=='Washington DC').show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1587,
     "status": "ok",
     "timestamp": 1724333820905,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "z0KQE2t2SfE8",
    "outputId": "4f025434-d1f0-45c7-ae3b-d98487a44201"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+\n",
      "|State|   Delays|\n",
      "+-----+---------+\n",
      "|   SC|  80666.0|\n",
      "|   AZ| 401793.0|\n",
      "|   LA| 199136.0|\n",
      "|   MN| 256811.0|\n",
      "|   NJ| 452791.0|\n",
      "|   OR| 109333.0|\n",
      "|   VA|  98016.0|\n",
      "| NULL| 397237.0|\n",
      "|   RI|  30760.0|\n",
      "|   WY|  15365.0|\n",
      "|   KY|  61156.0|\n",
      "|   NH|  20474.0|\n",
      "|   MI| 366486.0|\n",
      "|   NV| 474208.0|\n",
      "|   WI| 152311.0|\n",
      "|   ID|  22932.0|\n",
      "|   CA|1891919.0|\n",
      "|   CT|  54662.0|\n",
      "|   NE|  59376.0|\n",
      "|   MT|  19271.0|\n",
      "+-----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Query Sum of Flight Delays by State (for the US)\n",
    "spark.sql(\"select a.State, sum(f.delay) as Delays from flight f join airport a on a.IATA = f.origin where a.Country = 'USA' group by a.State\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1568,
     "status": "ok",
     "timestamp": 1724334858738,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "g69vgomWWpUU",
    "outputId": "41592e9a-3c4d-4102-e64b-7c6f40641ec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|State|sum(delay)|\n",
      "+-----+----------+\n",
      "|   SC|   80666.0|\n",
      "|   AZ|  401793.0|\n",
      "|   LA|  199136.0|\n",
      "|   MN|  256811.0|\n",
      "|   NJ|  452791.0|\n",
      "|   OR|  109333.0|\n",
      "|   VA|   98016.0|\n",
      "| NULL|  397237.0|\n",
      "|   RI|   30760.0|\n",
      "|   WY|   15365.0|\n",
      "|   KY|   61156.0|\n",
      "|   NH|   20474.0|\n",
      "|   MI|  366486.0|\n",
      "|   NV|  474208.0|\n",
      "|   WI|  152311.0|\n",
      "|   ID|   22932.0|\n",
      "|   CA| 1891919.0|\n",
      "|   CT|   54662.0|\n",
      "|   NE|   59376.0|\n",
      "|   MT|   19271.0|\n",
      "+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(flightPerf.select('delay', 'origin')\n",
    "                .join(airports.select('IATA','City','State'),flightPerf.origin==airports.IATA)\n",
    "                .groupby('State').agg({'delay':'sum'})\n",
    "                .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1954,
     "status": "ok",
     "timestamp": 1724333886558,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "f_Lw-uyYSi7D",
    "outputId": "49088dd8-024b-4182-bc8f-bfe00a945e7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+------+\n",
      "|         City|destination|Delays|\n",
      "+-------------+-----------+------+\n",
      "|Washington DC|        ABQ|     9|\n",
      "|Washington DC|        ALB|    95|\n",
      "|Washington DC|        ATL|    98|\n",
      "|Washington DC|        AUS|     9|\n",
      "|Washington DC|        BDL|    98|\n",
      "|Washington DC|        BNA|    99|\n",
      "|Washington DC|        BOS|    99|\n",
      "|Washington DC|        BTR|    61|\n",
      "|Washington DC|        BTV|    97|\n",
      "|Washington DC|        BUF|     9|\n",
      "|Washington DC|        CAE|    97|\n",
      "|Washington DC|        CHS|    95|\n",
      "|Washington DC|        CLE|    97|\n",
      "|Washington DC|        CLT|    99|\n",
      "|Washington DC|        CMH|    99|\n",
      "|Washington DC|        COS|    83|\n",
      "|Washington DC|        CRW|     8|\n",
      "|Washington DC|        CVG|     9|\n",
      "|Washington DC|        DAY|    96|\n",
      "|Washington DC|        DCA|     0|\n",
      "+-------------+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Query farest destination from where City is Washington\n",
    "spark.sql(\"select a.City, f.destination, max(f.delay) as Delays from flight f join airport a on a.IATA = f.origin where a.City = 'Washington DC' group by a.City, f.destination\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1159,
     "status": "ok",
     "timestamp": 1724336430889,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "FZrxR5mwcua7",
    "outputId": "7dd9a3fe-d851-415d-dc12-5698d0fa885a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-----+-----------+------------+--------------+----------------+-----------------+-------------------+\n",
      "|origin|destination|delay|origin_city|origin_state|origin_country|destination_city|destination_state|destination_country|\n",
      "+------+-----------+-----+-----------+------------+--------------+----------------+-----------------+-------------------+\n",
      "|   ABE|        ATL|    6|  Allentown|          PA|           USA|         Atlanta|               GA|                USA|\n",
      "|   ABE|        DTW|   -8|  Allentown|          PA|           USA|         Detroit|               MI|                USA|\n",
      "|   ABE|        ATL|   -2|  Allentown|          PA|           USA|         Atlanta|               GA|                USA|\n",
      "|   ABE|        ATL|   -4|  Allentown|          PA|           USA|         Atlanta|               GA|                USA|\n",
      "|   ABE|        ATL|   -4|  Allentown|          PA|           USA|         Atlanta|               GA|                USA|\n",
      "|   ABE|        ATL|    0|  Allentown|          PA|           USA|         Atlanta|               GA|                USA|\n",
      "|   ABE|        ATL|   10|  Allentown|          PA|           USA|         Atlanta|               GA|                USA|\n",
      "|   ABE|        ATL|   28|  Allentown|          PA|           USA|         Atlanta|               GA|                USA|\n",
      "|   ABE|        ATL|   88|  Allentown|          PA|           USA|         Atlanta|               GA|                USA|\n",
      "|   ABE|        ATL|    9|  Allentown|          PA|           USA|         Atlanta|               GA|                USA|\n",
      "|   ABE|        ATL|   -6|  Allentown|          PA|           USA|         Atlanta|               GA|                USA|\n",
      "|   ABE|        ATL|   69|  Allentown|          PA|           USA|         Atlanta|               GA|                USA|\n",
      "|   ABE|        DTW|    0|  Allentown|          PA|           USA|         Detroit|               MI|                USA|\n",
      "|   ABE|        ATL|   -3|  Allentown|          PA|           USA|         Atlanta|               GA|                USA|\n",
      "|   ABE|        DTW|    0|  Allentown|          PA|           USA|         Detroit|               MI|                USA|\n",
      "|   ABE|        ATL|    0|  Allentown|          PA|           USA|         Atlanta|               GA|                USA|\n",
      "|   ABE|        DTW|    0|  Allentown|          PA|           USA|         Detroit|               MI|                USA|\n",
      "|   ABE|        ATL|    0|  Allentown|          PA|           USA|         Atlanta|               GA|                USA|\n",
      "|   ABE|        ORD|    0|  Allentown|          PA|           USA|         Chicago|               IL|                USA|\n",
      "|   ABE|        DTW|    0|  Allentown|          PA|           USA|         Detroit|               MI|                USA|\n",
      "+------+-----------+-----+-----------+------------+--------------+----------------+-----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#one solution is merging everythin on one table, and filter on it\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df1 = airports.select('IATA','City','State','Country')\n",
    "df2 = flightPerf.select('origin','destination','delay')\n",
    "\n",
    "# First join: Merge df1 with df2 on the origin key\n",
    "merged_df = df2.join(df1, df2.origin == df1.IATA, how=\"left\")\n",
    "\n",
    "# Rename the columns from the first join with suffix _origin\n",
    "merged_df = merged_df.withColumnRenamed(\"City\", \"origin_city\") \\\n",
    "                     .withColumnRenamed(\"State\", \"origin_state\") \\\n",
    "                     .withColumnRenamed(\"Country\", \"origin_country\")\n",
    "\n",
    "# Drop the IATA column after the first join\n",
    "merged_df = merged_df.drop(\"IATA\")\n",
    "\n",
    "# Second join: Merge the result with df1 again on the destination key\n",
    "merged_df = merged_df.join(df1, merged_df.destination == df1.IATA, how=\"left\")\n",
    "\n",
    "# Rename the columns from the second join with suffix _destination\n",
    "merged_df = merged_df.withColumnRenamed(\"City\", \"destination_city\") \\\n",
    "                     .withColumnRenamed(\"State\", \"destination_state\") \\\n",
    "                     .withColumnRenamed(\"Country\", \"destination_country\")\n",
    "\n",
    "# Drop the IATA column after the second join\n",
    "merged_df = merged_df.drop(\"IATA\")\n",
    "\n",
    "# Show the final result\n",
    "merged_df.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1I1lPjZZ_EPV7miBKnqMRe2enXoBsAgDR",
     "timestamp": 1724328421426
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "name": "Ch4 - DataFrames",
  "notebookId": 4341522646494009,
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
