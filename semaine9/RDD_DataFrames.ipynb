{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJWNIvyMH-Ht"
   },
   "source": [
    "# RDD et DataFrames\n",
    "\n",
    "## RDD: Resilient Distributed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 53412,
     "status": "ok",
     "timestamp": 1724231412355,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "ail1ghmOMl5g"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T08:11:47.577290Z",
     "iopub.status.busy": "2024-08-23T08:11:47.577290Z",
     "iopub.status.idle": "2024-08-23T08:11:47.616931Z",
     "shell.execute_reply": "2024-08-23T08:11:47.615921Z",
     "shell.execute_reply.started": "2024-08-23T08:11:47.577290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T13:13:21.861135Z",
     "start_time": "2024-08-21T13:13:15.649133Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T08:11:49.166747Z",
     "iopub.status.busy": "2024-08-23T08:11:49.166747Z",
     "iopub.status.idle": "2024-08-23T08:11:54.157146Z",
     "shell.execute_reply": "2024-08-23T08:11:54.157146Z",
     "shell.execute_reply.started": "2024-08-23T08:11:49.166747Z"
    },
    "executionInfo": {
     "elapsed": 14953,
     "status": "ok",
     "timestamp": 1724231427294,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "YFskx2ZvH-Hv",
    "outputId": "6108a66c-7d43-479c-9be7-405318317cd0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>RDD_Examples</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=RDD_Examples>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create entry points to spark\n",
    "try:\n",
    "    sc.stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"RDD_Examples\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_R1HksoH-Hy"
   },
   "source": [
    "### Creating RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80VT1N38H-Hz"
   },
   "source": [
    "There are two ways to create an RDD in PySpark. You can parallelize a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T13:13:24.508320Z",
     "start_time": "2024-08-21T13:13:23.747034Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T08:11:54.159913Z",
     "iopub.status.busy": "2024-08-23T08:11:54.159913Z",
     "iopub.status.idle": "2024-08-23T08:11:55.452947Z",
     "shell.execute_reply": "2024-08-23T08:11:55.451941Z",
     "shell.execute_reply.started": "2024-08-23T08:11:54.159913Z"
    },
    "executionInfo": {
     "elapsed": 1325,
     "status": "ok",
     "timestamp": 1724231460962,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "CJiWsWO2H-H0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Amber', 22), ('Alfred', 23), ('Skye', 4), ('Albert', 12), ('Amber', 9)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.parallelize(\n",
    "    [('Amber', 22), ('Alfred', 23), ('Skye',4), ('Albert', 12),\n",
    "     ('Amber', 9)])\n",
    "data.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfGBi0_1H-H1"
   },
   "source": [
    "or read from a repository (a file or a database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrKvYJXYH-Im"
   },
   "source": [
    "## Application 1:\n",
    "\n",
    "On considère le fichier etudiants.csv (fourni), Ecrire un code Pyspark , en utilisant/manipulant des RDD, qui permet de:\n",
    "\n",
    "1- charger les données\n",
    "\n",
    "2- effectuer un filtrage pour exclure les lignes des étudiant de \"UniversiteC\"\n",
    "\n",
    "3- extraire les noms des étudiants\n",
    "\n",
    "4- retourner le nombre d'étudiants distincts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T13:16:58.536360Z",
     "start_time": "2024-08-21T13:16:58.529984Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-21T13:23:47.034180Z",
     "iopub.status.busy": "2024-08-21T13:23:47.034180Z",
     "iopub.status.idle": "2024-08-21T13:23:47.042360Z",
     "shell.execute_reply": "2024-08-21T13:23:47.042306Z",
     "shell.execute_reply.started": "2024-08-21T13:23:47.034180Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS']= \"notebook\"\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T13:19:15.146148Z",
     "start_time": "2024-08-21T13:19:15.139793Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T08:12:04.879452Z",
     "iopub.status.busy": "2024-08-23T08:12:04.879452Z",
     "iopub.status.idle": "2024-08-23T08:12:04.888531Z",
     "shell.execute_reply": "2024-08-23T08:12:04.888531Z",
     "shell.execute_reply.started": "2024-08-23T08:12:04.879452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "Path('etudiants.csv').exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T13:19:26.102148Z",
     "start_time": "2024-08-21T13:19:24.857889Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T08:12:06.656154Z",
     "iopub.status.busy": "2024-08-23T08:12:06.656154Z",
     "iopub.status.idle": "2024-08-23T08:12:07.204912Z",
     "shell.execute_reply": "2024-08-23T08:12:07.204912Z",
     "shell.execute_reply.started": "2024-08-23T08:12:06.656154Z"
    },
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1724233103261,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "A1yTOc1zH-Im"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dupont,Jean,UniversiteA,Data Science',\n",
       " 'Martin,Marie,UniversiteB,Statistics',\n",
       " 'Lefevre,Paul,UniversiteA,Machine Learning',\n",
       " 'Girard,Sophie,UniversiteC,Big Data',\n",
       " 'Dubois,Philippe,UniversiteB,Data Engineering',\n",
       " 'Lefort,Isabelle,UniversiteC,Statistics',\n",
       " 'Martin,Marie,UniversiteA,Data Science']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data=sc.textFile(filename)\n",
    "data=sc.textFile('etudiants.csv')\n",
    "data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T13:19:31.816245Z",
     "start_time": "2024-08-21T13:19:29.958064Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T08:12:07.210242Z",
     "iopub.status.busy": "2024-08-23T08:12:07.204912Z",
     "iopub.status.idle": "2024-08-23T08:12:09.409850Z",
     "shell.execute_reply": "2024-08-23T08:12:09.409850Z",
     "shell.execute_reply.started": "2024-08-23T08:12:07.210242Z"
    },
    "executionInfo": {
     "elapsed": 589,
     "status": "ok",
     "timestamp": 1724233149481,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "Dq8G8cAkTURV",
    "outputId": "49fdf540-f7f8-4404-b4d6-6c259f3c19ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dupont,Jean,UniversiteA,Data',\n",
       " 'Science',\n",
       " 'Martin,Marie,UniversiteB,Statistics',\n",
       " 'Lefevre,Paul,UniversiteA,Machine',\n",
       " 'Learning',\n",
       " 'Girard,Sophie,UniversiteC,Big',\n",
       " 'Data',\n",
       " 'Dubois,Philippe,UniversiteB,Data',\n",
       " 'Engineering',\n",
       " 'Lefort,Isabelle,UniversiteC,Statistics',\n",
       " 'Martin,Marie,UniversiteA,Data',\n",
       " 'Science']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# effectuer un filtrage pour exclure les lignes des étudiant de \"UniversiteC\n",
    "data_filtered = data.flatMap(lambda line: line.split())\n",
    "data_filtered.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T13:19:31.816245Z",
     "start_time": "2024-08-21T13:19:29.958064Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T08:12:09.409850Z",
     "iopub.status.busy": "2024-08-23T08:12:09.409850Z",
     "iopub.status.idle": "2024-08-23T08:12:11.086657Z",
     "shell.execute_reply": "2024-08-23T08:12:11.086657Z",
     "shell.execute_reply.started": "2024-08-23T08:12:09.409850Z"
    },
    "executionInfo": {
     "elapsed": 589,
     "status": "ok",
     "timestamp": 1724233149481,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "Dq8G8cAkTURV",
    "outputId": "49fdf540-f7f8-4404-b4d6-6c259f3c19ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dupont,Jean,UniversiteA,Data Science',\n",
       " 'Martin,Marie,UniversiteB,Statistics',\n",
       " 'Lefevre,Paul,UniversiteA,Machine Learning',\n",
       " 'Dubois,Philippe,UniversiteB,Data Engineering',\n",
       " 'Martin,Marie,UniversiteA,Data Science']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# effectuer un filtrage pour exclure les lignes des étudiant de \"UniversiteC\n",
    "data_filtered = data.filter(lambda line: \"UniversiteC\" not in line)\n",
    "data_filtered.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T08:12:11.086657Z",
     "iopub.status.busy": "2024-08-23T08:12:11.086657Z",
     "iopub.status.idle": "2024-08-23T08:12:12.741670Z",
     "shell.execute_reply": "2024-08-23T08:12:12.741670Z",
     "shell.execute_reply.started": "2024-08-23T08:12:11.086657Z"
    },
    "executionInfo": {
     "elapsed": 975,
     "status": "ok",
     "timestamp": 1724233204959,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "8ZmQX4DqH-In",
    "outputId": "a93fe29c-826f-4190-c27a-2b4e27a0c75c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dupont', 'Martin', 'Lefevre', 'Dubois', 'Martin']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extraire les noms des étudiants\n",
    "\n",
    "names = data_filtered.map(lambda line: line.split(',')[0])\n",
    "names.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T08:12:12.741670Z",
     "iopub.status.busy": "2024-08-23T08:12:12.741670Z",
     "iopub.status.idle": "2024-08-23T08:12:16.359482Z",
     "shell.execute_reply": "2024-08-23T08:12:16.358357Z",
     "shell.execute_reply.started": "2024-08-23T08:12:12.741670Z"
    },
    "executionInfo": {
     "elapsed": 2807,
     "status": "ok",
     "timestamp": 1724233230718,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "mdIY-TIQH-In",
    "outputId": "80a071fd-0e8b-4096-f548-8adb177f0e53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct students: 4\n"
     ]
    }
   ],
   "source": [
    "# retourner le nombre d'étudiants distincts.\n",
    "\n",
    "distinct_names = names.distinct()\n",
    "num_distinct_names = distinct_names.count()\n",
    "print(\"Number of distinct students:\", num_distinct_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiS-A85TH-Io"
   },
   "source": [
    "## DataFrame object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qj2b7vbH-Io"
   },
   "source": [
    "* Create SparkContext and SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T08:12:16.360749Z",
     "iopub.status.busy": "2024-08-23T08:12:16.360749Z",
     "iopub.status.idle": "2024-08-23T08:12:17.550016Z",
     "shell.execute_reply": "2024-08-23T08:12:17.548959Z",
     "shell.execute_reply.started": "2024-08-23T08:12:16.360749Z"
    },
    "executionInfo": {
     "elapsed": 2038,
     "status": "ok",
     "timestamp": 1724233239250,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "AcHhueKsH-Io"
   },
   "outputs": [],
   "source": [
    "# create entry points to spark\n",
    "try:\n",
    "    sc.stop()\n",
    "except:\n",
    "    pass\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "sc=SparkContext()\n",
    "spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7V7FM2urH-Ip"
   },
   "source": [
    "### Create a DataFrame object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGeh94btH-Ip"
   },
   "source": [
    "#### Creat DataFrame by reading a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T08:14:05.783726Z",
     "iopub.status.busy": "2024-08-23T08:14:05.782692Z",
     "iopub.status.idle": "2024-08-23T08:14:06.153127Z",
     "shell.execute_reply": "2024-08-23T08:14:06.153127Z",
     "shell.execute_reply.started": "2024-08-23T08:14:05.783726Z"
    },
    "executionInfo": {
     "elapsed": 10608,
     "status": "ok",
     "timestamp": 1724233946454,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "cTSvF41eH-Iq",
    "outputId": "2a6558ca-a3ff-438a-c79e-7fa293de443c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----------+----------------+\n",
      "|Dupont |Jean    |UniversiteA|Data Science    |\n",
      "+-------+--------+-----------+----------------+\n",
      "|Martin |Marie   |UniversiteB|Statistics      |\n",
      "|Lefevre|Paul    |UniversiteA|Machine Learning|\n",
      "|Girard |Sophie  |UniversiteC|Big Data        |\n",
      "|Dubois |Philippe|UniversiteB|Data Engineering|\n",
      "|Lefort |Isabelle|UniversiteC|Statistics      |\n",
      "+-------+--------+-----------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtcars = spark.read.csv(path='etudiants.csv',\n",
    "                        sep=',',\n",
    "                        encoding='UTF-8',\n",
    "                        comment=None,\n",
    "                        header=True,\n",
    "                        inferSchema=True)\n",
    "mtcars.show(n=5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJISyBN_H-Ir"
   },
   "source": [
    "#### Create DataFrame with `createDataFrame` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62YVXOfLH-Ir"
   },
   "source": [
    "##### From an RDD\n",
    "\n",
    "Elements in RDD has to be an Row object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T08:14:07.599068Z",
     "iopub.status.busy": "2024-08-23T08:14:07.597034Z",
     "iopub.status.idle": "2024-08-23T08:14:07.695065Z",
     "shell.execute_reply": "2024-08-23T08:14:07.693069Z",
     "shell.execute_reply.started": "2024-08-23T08:14:07.599068Z"
    },
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1724233806327,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "HQ6OUJwCH-Is",
    "outputId": "88bc3b2c-8eca-4492-d8c7-e0d727d6d1bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(x=[1, 2, 3], y=['a', 'b', 'c']), Row(x=[4, 5, 6], y=['e', 'f', 'g'])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "rdd = sc.parallelize([\n",
    "    Row(x=[1,2,3], y=['a','b','c']),\n",
    "    Row(x=[4,5,6], y=['e','f','g'])\n",
    "])\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T08:14:07.950326Z",
     "iopub.status.busy": "2024-08-23T08:14:07.950326Z",
     "iopub.status.idle": "2024-08-23T08:14:34.443081Z",
     "shell.execute_reply": "2024-08-23T08:14:34.442573Z",
     "shell.execute_reply.started": "2024-08-23T08:14:07.950326Z"
    },
    "executionInfo": {
     "elapsed": 3803,
     "status": "ok",
     "timestamp": 1724233963874,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "pjI6GKEwH-It",
    "outputId": "ccb46e13-d2f2-4a11-e8d6-9eb83b8790ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|        x|        y|\n",
      "+---------+---------+\n",
      "|[1, 2, 3]|[a, b, c]|\n",
      "|[4, 5, 6]|[e, f, g]|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(rdd)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHQWi0tiH-Iu"
   },
   "source": [
    "##### From pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T08:14:34.443081Z",
     "iopub.status.busy": "2024-08-23T08:14:34.443081Z",
     "iopub.status.idle": "2024-08-23T08:14:34.485344Z",
     "shell.execute_reply": "2024-08-23T08:14:34.485344Z",
     "shell.execute_reply.started": "2024-08-23T08:14:34.443081Z"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1724233963874,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "sF3I26o7H-Iu",
    "outputId": "a7ed62d4-78e0-486c-99ef-14135e4ccb37"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[a, b, c]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4, 5, 6]</td>\n",
       "      <td>[e, f, g]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x          y\n",
       "0  [1, 2, 3]  [a, b, c]\n",
       "1  [4, 5, 6]  [e, f, g]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pdf = pd.DataFrame({\n",
    "    'x': [[1,2,3], [4,5,6]],\n",
    "    'y': [['a','b','c'], ['e','f','g']]\n",
    "})\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T08:14:34.485344Z",
     "iopub.status.busy": "2024-08-23T08:14:34.485344Z",
     "iopub.status.idle": "2024-08-23T08:14:47.637660Z",
     "shell.execute_reply": "2024-08-23T08:14:47.637660Z",
     "shell.execute_reply.started": "2024-08-23T08:14:34.485344Z"
    },
    "executionInfo": {
     "elapsed": 892,
     "status": "ok",
     "timestamp": 1724233975071,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "uUQ9qMG9H-Iv",
    "outputId": "c8b10388-abb8-4134-a213-0f6a2843052d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|        x|        y|\n",
      "+---------+---------+\n",
      "|[1, 2, 3]|[a, b, c]|\n",
      "|[4, 5, 6]|[e, f, g]|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(pdf)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Amk5oQxYH-Iv"
   },
   "source": [
    "##### From a list\n",
    "\n",
    "Each element in the list becomes an Row in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T08:14:47.637660Z",
     "iopub.status.busy": "2024-08-23T08:14:47.637660Z",
     "iopub.status.idle": "2024-08-23T08:15:00.818405Z",
     "shell.execute_reply": "2024-08-23T08:15:00.817395Z",
     "shell.execute_reply.started": "2024-08-23T08:14:47.637660Z"
    },
    "executionInfo": {
     "elapsed": 1949,
     "status": "ok",
     "timestamp": 1724233977723,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "rULjMf5JH-Iv",
    "outputId": "36114819-2fbe-4ea2-cc58-1451ea913009"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|letter|number|\n",
      "+------+------+\n",
      "|     a|     1|\n",
      "|     b|     2|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_list = [['a', 1], ['b', 2]]\n",
    "df = spark.createDataFrame(my_list, ['letter', 'number'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T08:15:00.821406Z",
     "iopub.status.busy": "2024-08-23T08:15:00.820405Z",
     "iopub.status.idle": "2024-08-23T08:15:00.827570Z",
     "shell.execute_reply": "2024-08-23T08:15:00.826559Z",
     "shell.execute_reply.started": "2024-08-23T08:15:00.821406Z"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1724233977724,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "E0Z_E8WOH-Iw",
    "outputId": "e0a5a41d-2480-4caa-ea9e-c6cf83d6a725"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('letter', 'string'), ('number', 'bigint')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T08:15:00.829956Z",
     "iopub.status.busy": "2024-08-23T08:15:00.828581Z",
     "iopub.status.idle": "2024-08-23T08:15:13.816991Z",
     "shell.execute_reply": "2024-08-23T08:15:13.815984Z",
     "shell.execute_reply.started": "2024-08-23T08:15:00.829956Z"
    },
    "executionInfo": {
     "elapsed": 1495,
     "status": "ok",
     "timestamp": 1724233979214,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "3iQ4GBmYH-Iw",
    "outputId": "d5cb7fa4-245a-4337-cc15-b4565e10881b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+\n",
      "|my_column| _2|\n",
      "+---------+---+\n",
      "|        a|  1|\n",
      "|        b|  2|\n",
      "+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_list = [['a', 1], ['b', 2]]\n",
    "df = spark.createDataFrame(my_list, ['my_column'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T08:15:13.817992Z",
     "iopub.status.busy": "2024-08-23T08:15:13.817992Z",
     "iopub.status.idle": "2024-08-23T08:15:13.823366Z",
     "shell.execute_reply": "2024-08-23T08:15:13.823366Z",
     "shell.execute_reply.started": "2024-08-23T08:15:13.817992Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1724233979215,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "ZJGS4QPXH-Ix",
    "outputId": "dea56223-c5c6-4da1-a297-eee2aaa277b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('my_column', 'string'), ('_2', 'bigint')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRW3_XmuH-Ix"
   },
   "source": [
    "The following code generates a DataFrame consisting of two columns, each column is a vector column.\n",
    "\n",
    "Why vector columns are generated in this case?\n",
    "In this case, the list **my_list** has only one element, a tuple. Therefore, the DataFrame has only one row. This tuple has two elements. Therefore, it generates a two-columns DataFrame. Each element in the tuple is a list, so the resulting columns are vector columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T08:15:13.825859Z",
     "iopub.status.busy": "2024-08-23T08:15:13.825859Z",
     "iopub.status.idle": "2024-08-23T08:15:27.285238Z",
     "shell.execute_reply": "2024-08-23T08:15:27.285238Z",
     "shell.execute_reply.started": "2024-08-23T08:15:13.825859Z"
    },
    "executionInfo": {
     "elapsed": 1762,
     "status": "ok",
     "timestamp": 1724233980973,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "uuyDU5N7H-Ix",
    "outputId": "cd4256b4-4802-47e7-aba9-f4bd10a51910"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|     x|     y|\n",
      "+------+------+\n",
      "|[a, 1]|[b, 2]|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_list = [(['a', 1], ['b', 2])]\n",
    "df = spark.createDataFrame(my_list, ['x', 'y'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4ZoWVbAH-Iz"
   },
   "source": [
    "\n",
    "\n",
    "### Column instance\n",
    "\n",
    "Column instances can be created in two ways:\n",
    "\n",
    "1. directly select a column out of a *DataFrame*: `df.colName`\n",
    "2. create from a column expression: `df.colName + 1`\n",
    "\n",
    "Technically, there is only one way to create a column instance. Column expressions start from a column instance.\n",
    "\n",
    "**Remember how to create column instances, because this is usually the starting point if we want to operate DataFrame columns.**\n",
    "\n",
    "The column classes come with some methods that can operate on a column instance. ***However, almost all functions from the `pyspark.sql.functions` module take one or more column instances as argument(s)***. These functions are important for data manipulation tools.\n",
    "\n",
    "#### DataFrame column methods\n",
    "\n",
    "##### Methods that take column names as arguments:\n",
    "\n",
    "* `corr(col1, col2)`: two column names.\n",
    "* `cov(col1, col2)`: two column names.\n",
    "* `crosstab(col1, col2)`: two column names.\n",
    "* `describe(*cols)`: ***`*cols` refers to only column names (strings).***\n",
    "\n",
    "##### Methods that take column names or column expressions or **both** as arguments:\n",
    "\n",
    "* `cube(*cols)`: column names (string) or column expressions or **both**.\n",
    "* `drop(*cols)`: ***a list of column names OR a single column expression.***\n",
    "* `groupBy(*cols)`: column name (string) or column expression or **both**.\n",
    "* `rollup(*cols)`: column name (string) or column expression or **both**.\n",
    "* `select(*cols)`: column name (string) or column expression or **both**.\n",
    "* `sort(*cols, **kwargs)`: column name (string) or column expression or **both**.\n",
    "* `sortWithinPartitions(*cols, **kwargs)`: column name (string) or column expression or **both**.\n",
    "* `orderBy(*cols, **kwargs)`: column name (string) or column expression or **both**.\n",
    "* `sampleBy(col, fractions, sed=None)`: a column name.\n",
    "* `toDF(*cols)`: **a list of column names (string).**\n",
    "* `withColumn(colName, col)`: `colName` refers to column name; `col` refers to a column expression.\n",
    "* `withColumnRenamed(existing, new)`: takes column names as arguments.\n",
    "* `filter(condition)`: ***condition** refers to a column expression that returns `types.BooleanType` of values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfAjKrpjH-Iz"
   },
   "source": [
    "## Application 2:\n",
    "\n",
    "On considère les structures de données ci dessous:\n",
    "\n",
    "1 -Créer un DataFrame pyspark à partir d'un dataframe pandas\n",
    "\n",
    "2 -Créer un DataFrame pyspark à partir de RDD de liste de tuples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ImH4rQSH-I0"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6LUf-GiH-I0"
   },
   "source": [
    "* Créer une DataFrame à partir de pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T08:15:27.286244Z",
     "iopub.status.busy": "2024-08-23T08:15:27.286244Z",
     "iopub.status.idle": "2024-08-23T08:15:28.152395Z",
     "shell.execute_reply": "2024-08-23T08:15:28.149632Z",
     "shell.execute_reply.started": "2024-08-23T08:15:27.286244Z"
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1724234040837,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "yNnFL130H-I0",
    "outputId": "181596c4-a207-473f-b904-3ddaabe7c8fb"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/etudiants.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# read csv with pandas\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m pandas_df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/etudiants.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m pandas_df\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pyspark2\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pyspark2\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pyspark2\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pyspark2\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pyspark2\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/etudiants.csv'"
     ]
    }
   ],
   "source": [
    "# read csv with pandas\n",
    "pandas_df=pd.read_csv(\"/content/etudiants.csv\")\n",
    "pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pipandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-08-23T08:12:55.021055Z",
     "iopub.status.idle": "2024-08-23T08:12:55.021055Z",
     "shell.execute_reply": "2024-08-23T08:12:55.021055Z",
     "shell.execute_reply.started": "2024-08-23T08:12:55.021055Z"
    },
    "executionInfo": {
     "elapsed": 1334,
     "status": "ok",
     "timestamp": 1724234070789,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "zbYgT_3xH-I0",
    "outputId": "5231b112-e729-45cb-c4c1-5b40c41a7056"
   },
   "outputs": [],
   "source": [
    "#convert pandas_df to spark df\n",
    "\n",
    "spark_df = spark.createDataFrame(pandas_df)\n",
    "spark_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hpd16MwqH-I1"
   },
   "source": [
    "* Créer une DataFrame à partir de RDD de liste de tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-23T08:12:55.022055Z",
     "iopub.status.idle": "2024-08-23T08:12:55.023056Z",
     "shell.execute_reply": "2024-08-23T08:12:55.023056Z",
     "shell.execute_reply.started": "2024-08-23T08:12:55.022055Z"
    },
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1724234131031,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "t4RjRTg7XNVE"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-23T08:12:55.024056Z",
     "iopub.status.idle": "2024-08-23T08:12:55.025096Z",
     "shell.execute_reply": "2024-08-23T08:12:55.025096Z",
     "shell.execute_reply.started": "2024-08-23T08:12:55.025096Z"
    },
    "executionInfo": {
     "elapsed": 235,
     "status": "ok",
     "timestamp": 1724234135636,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "unpjNYbPH-I1"
   },
   "outputs": [],
   "source": [
    "list_tuple = [\n",
    "    (1, 2., 'string1', date(2000, 1, 1), datetime(2000, 1, 1, 12, 0)),\n",
    "    (2, 3., 'string2', date(2000, 2, 1), datetime(2000, 1, 2, 12, 0)),\n",
    "    (3, 4., 'string3', date(2000, 3, 1), datetime(2000, 1, 3, 12, 0))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-08-23T08:12:55.026104Z",
     "iopub.status.idle": "2024-08-23T08:12:55.027116Z",
     "shell.execute_reply": "2024-08-23T08:12:55.026104Z",
     "shell.execute_reply.started": "2024-08-23T08:12:55.026104Z"
    },
    "executionInfo": {
     "elapsed": 2138,
     "status": "ok",
     "timestamp": 1724234173331,
     "user": {
      "displayName": "laien wu",
      "userId": "17614188222197305014"
     },
     "user_tz": -120
    },
    "id": "apTtxaygXRcJ",
    "outputId": "156f5ff3-f51f-4de2-9062-1f8a7d9f61f9"
   },
   "outputs": [],
   "source": [
    "# create spark df with list_tuple\n",
    "\n",
    "rdd = spark.sparkContext.parallelize(list_tuple)\n",
    "df_2 = spark.createDataFrame(rdd, schema=['int', 'float', 'string', 'date', 'datetime'])\n",
    "df_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9od9fQdnH-I3"
   },
   "source": [
    "## Ressources utiles:\n",
    "\n",
    "La doc de Spark contient un User Guide très “user friendly”: https://spark.apache.org/docs/latest/\n",
    "\n",
    "Et une version détaillée de l’API Spark (dans différents langages),\n",
    "\n",
    "voici la version python:\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/index.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HxfY7d8bH-I3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1aolLPXQZaOylqj3JcXrMW9xIvdLlLErN",
     "timestamp": 1724231328510
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
