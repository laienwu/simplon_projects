{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MongoDB\n",
    "===========\n",
    "\n",
    "\n",
    "\n",
    "a ``MongoClient`` instance provides connection to MongoDB Server, each server can host multiple databases which can be retrieved with ``connection.database_name`` which can then contain multiple ``collections`` with different documents."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pymongo import MongoClient, InsertOne, DeleteOne, DeleteMany, UpdateOne, UpdateMany\n",
    "import pymongo\n",
    "from decimal import Decimal\n",
    "from bson.json_util import loads\n",
    "from bson.objectid import ObjectId"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "try:\n",
    "    load_dotenv()\n",
    "    usr = os.getenv(\"mongo_usr\")\n",
    "    pwd = os.getenv(\"mongo_pw\")\n",
    "except Exception as e:\n",
    "    exit()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "client = MongoClient(f'mongodb://{usr}:{pwd}@localhost:27017/')\n",
    "client"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a database called ``phonebook`` and a collection called ``people``\n",
    "\n",
    "Once the database is retrieved, collections can be accessed as attributes of the database itself.\n",
    "\n",
    "A MongoDB document is actually just a Python Dictionary, inserting a document is as simple as telling pymongo to insert the dictionary into the collection. Each document can have its own structure, can contain different data and you are not required to declare and structure of the collection. Not existing collections will be automatically created on the insertion of the first document\n",
    "\n",
    "Insert an object in the database: ``data = {'name': 'Alessandro', 'phone': '+39123456789'}``"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "db = client['phonebook']\n",
    "collection = db['people']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "data = {'name': 'Alessandro', 'phone': '+39123456789'}\n",
    "collection.insert_one(data)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching back inserted document can be done using ``find`` and ``find_one`` methods of collections. Both methods accept a query expression that filters the returned documents. Omitting it means retrieving all the documents (or in case of find_one the first document)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": "collection.find_one()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters in mongodb are described by Documents themselves, so in case of PyMongo they are dictionaries too.\n",
    "A filter can be specified in the form ``{'field': value}``. \n",
    "By default filtering is performed by *equality* comparison, this can be changed by specifying a query operator in place of the value.\n",
    "\n",
    "Query operators by convention start with a ``$`` sign and can be specified as ``{'field': {'operator': value}}``.\n",
    "Full list of query operators is available at https://docs.mongodb.org/manual/reference/operator/query/\n",
    "\n",
    "Find a person that has an object id greather than ``53b30ff57ab71c051823b031``we can achieve that with using ``find_one``:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": "collection.find_one({\"_id\": {\"$gt\": ObjectId(\"53b30ff57ab71c051823b031\")}})",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating Documents\n",
    "---------------------\n",
    "\n",
    "Updating documents in MongoDB can be performed with the ``update_one`` or ``update_many`` method of the collection. Updating is actually one of the major sources of issues for new users as it doesn't change values in document like it does on SQL based databases, but instead it replaces the document with a new one.\n",
    "\n",
    "What you usually want to do is actually using the ``$set`` operator which changes the existing document instead of replacing it with a new one. Read docs: https://pymongo.readthedocs.io/en/stable/api/pymongo/collection.html#pymongo.collection.Collection.update_one"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Find the document with name Alessandro and print it\n",
    "print(collection.find_one({'name': {\"$eq\": \"Alessandro\"}}))\n",
    "\n",
    "# Update the name to John and print the update \n",
    "collection.update_one({\"name\": \"Alessandro\"}, {\"$set\": {\"name\": \"John\"}})\n",
    "collection.find_one()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SubDocuments\n",
    "--------------\n",
    "\n",
    "The real power of mongodb is released when you use subdocuments.\n",
    "\n",
    "As each mongodb document is a JSON object (actually BSON, but that doesn't change much for the user), it can contain any data which is valid in JSON. Including other documents and arrays. This replaces \"relations\" between collections in multiple use cases and it's heavily more efficient as it returns all the data in a single query instead of having to perform multiple queries to retrieve related data.\n",
    "\n",
    "For example if you want to store a blog post in mongodb you might actually store everything, including author data and tags inside the blogpost itself:\n",
    "\n",
    "- Create a collection ``blog``\n",
    "- Insert the following document : \n",
    "```{'title': 'MongoDB is great!',\n",
    "                'author': {'name': 'Alessandro',\n",
    "                           'surname': 'Molina',\n",
    "                           'avatar': 'weblink'},\n",
    "                'tags': ['mongodb', 'web', 'scaling']}"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": "db['blog']",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "db.blog.insert_one({'title': 'MongoDB is great!',\n",
    "                    'author': {'name': 'Alessandro',\n",
    "                               'surname': 'Molina',\n",
    "                               'avatar': 'weblink'},\n",
    "                    'tags': ['mongodb', 'web', 'scaling']})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "db.blog.find_one({'title': 'MongoDB is great!'})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": "list(db.blog.find({'tags': 'mongodb'}))",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregation Pipeline\n",
    "----------------------\n",
    "\n",
    "The aggreation pipeline provided by the aggreation framework is a powerful feature in MongoDB that permits to perform complex data analysis by passing the documents through a pipeline of operations.\n",
    "\n",
    "MongoDB was created with the cover philosophy that you are going to store your documents depending on the way you are going to read them. So to properly design your schema you need to know how you are going to use the documents. While this approach provides great performance benefits and is more concrete in case of web application, it might not always be feasible.\n",
    "\n",
    "In case you need to perform some kind of analysis your documents are not optimized for, you can rely on the aggreation framework to create a pipeline that transforms them in a way more practical for the kind of analysis you need.\n",
    "\n",
    "### How it works\n",
    "\n",
    "The aggregation pipeline is a list of operations that gets executed one after the other on the documents of the collections. The first operation will be performed on all the documents, while successive operations are performed on the result of the previous steps.\n",
    "\n",
    "If steps are able to take advantage of **indexes** they will, that is the case for a **match** or **sort** operator, if it appears at the begin of the pipeline. All operators start with a <span><strong>$</strong></span> sign\n",
    "\n",
    "### Stage Operators\n",
    "\n",
    "\n",
    "* **project**\tReshapes each document in the stream, such as by adding new fields or removing existing fields. For each input document, outputs one document.\n",
    "* **match**\tFilters the document stream to allow only matching documents to pass unmodified into the next pipeline stage. **match** uses standard MongoDB queries. For each input document, outputs either one document (a match) or zero documents (no match).\n",
    "* **limit**\tPasses the first n documents unmodified to the pipeline where n is the specified limit. For each input document, outputs either one document (for the first n documents) or zero documents (after the first n documents).\n",
    "* **skip**\tSkips the first n documents where n is the specified skip number and passes the remaining documents unmodified to the pipeline. For each input document, outputs either zero documents (for the first n documents) or one document (if after the first n documents).\n",
    "* **unwind**\tDeconstructs an array field from the input documents to output a document for each element. Each output document replaces the array with an element value. For each input document, outputs n documents where n is the number of array elements and can be zero for an empty array.\n",
    "* **group**\tGroups input documents by a specified identifier expression and applies the accumulator expression(s), if specified, to each group. Consumes all input documents and outputs one document per each distinct group. The output documents only contain the identifier field and, if specified, accumulated fields.\n",
    "* **sort**\tReorders the document stream by a specified sort key. Only the order changes; the documents remain unmodified. For each input document, outputs one document.\n",
    "* **geoNear**\tReturns an ordered stream of documents based on the proximity to a geospatial point. Incorporates the functionality of **match**, **sort**, and **limit** for geospatial data. The output documents include an additional distance field and can include a location identifier field.\n",
    "* **out**\tWrites the resulting documents of the aggregation pipeline to a collection. To use the $out stage, it must be the last stage in the pipeline.\n",
    "\n",
    "#### Expression Operators\n",
    "\n",
    "Each stage operator can work with one or more **expression operator** which allow to perform actions during that stage, for a list of expression operators see https://docs.mongodb.org/manual/reference/operator/aggregation/#expression-operators\n",
    "\n",
    "### Pipeline Examples\n",
    "\n",
    "use the full listingsAndReviews json (Google Drive)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if \"pipe_example\" in client.test.list_collection_names():\n",
    "    client.test.pipe_example.drop()\n",
    "\n",
    "qa = client.test.pipe_example"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result = []\n",
    "with open('../data/listingAndReviews.json', 'r', encoding='utf8') as f:\n",
    "    for jsonObj in f:\n",
    "        try:\n",
    "            my_json = loads(jsonObj)\n",
    "            result.append(InsertOne(my_json))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing JSON: {e},[{my_json['price']}\")\n",
    "\n",
    "qa.bulk_write(result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Q1 Find the total number of listings in Sydney\n",
    "qa.count_documents({'address.market': 'Sydney'})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Q2 Show the most 5 popular market  with the largest number of properties\n",
    "pipeline = [\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$address.market\",\n",
    "        \"property_count\": {\"$sum\": 1}\n",
    "    }\n",
    "    },\n",
    "    {\"$sort\": {\n",
    "        \"property_count\": -1  # -1 for descending order\n",
    "    }\n",
    "    },\n",
    "    {\"$limit\": 5}\n",
    "]\n",
    "results = list(qa.aggregate(pipeline))\n",
    "results"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Q3 count of properties and average price per night by most populate market\n",
    "pipeline = [\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$address.market\",\n",
    "        \"property_count\": {\"$sum\": 1},\n",
    "        \"average_price\": {\"$avg\": {\"$trunc\": [{\"$toDecimal\": \"$price\"}, 2]}},\n",
    "    }\n",
    "    },\n",
    "\n",
    "    {\"$sort\": {\n",
    "        \"property_count\": -1\n",
    "    }\n",
    "    },\n",
    "    {\"$limit\": 5}\n",
    "]\n",
    "\n",
    "results = list(qa.aggregate(pipeline))\n",
    "results"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Q4 Choose 2 amenities of your choice and check the review scores and the price of the listings with those amenities \n",
    "chosen_amenities = [\"Wifi\", \"Kitchen\"]\n",
    "\n",
    "query = {\n",
    "    \"amenities\": {\n",
    "        \"$all\": chosen_amenities\n",
    "    }\n",
    "}\n",
    "\n",
    "project = {\n",
    "    \"name\": 1,\n",
    "    \"amenities\": 1,\n",
    "    \"review_scores\": 1,\n",
    "    \"total_price\": 1\n",
    "}\n",
    "\n",
    "listings = list(qa.find(query, project).sort(\"price\", -1))\n",
    "print(len(listings))\n",
    "# listings"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Q4 Choose 2 amenities of your choice and check the review scores and the price of the listings with those amenities \n",
    "# amenities_to_check = [\"Wifi\", \"Kitchen\"]\n",
    "# \n",
    "# pipeline = [\n",
    "#     {\n",
    "#         \"$match\": {\n",
    "#             \"amenities\": {\"$all\": amenities_to_check}\n",
    "#         }\n",
    "#     },\n",
    "#     {\n",
    "#         \"$group\": {\n",
    "#             \"_id\": \"$amenities\",\n",
    "#             \"sum_review_score_value\": {\"$avg\":\"$review_score.review_scores_value\"},\n",
    "#             # \"sum_review_score_value\": {\"$round\":{\"$avg\": [{\"review_scores\":{\"review_scores_value\"}},2]}},\n",
    "#             \"sum_price\": {\"$sum\": \"$price\"},\n",
    "#         }\n",
    "#     }\n",
    "# ]\n",
    "# results = list(qa.aggregate(pipeline))\n",
    "# results  #seems not working"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#groupby amenities and get price on it ( pipeline making purpose)\n",
    "pipeline = [\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"amenities_str\": {\"$reduce\": {\n",
    "                \"input\": \"$amenities\",\n",
    "                \"initialValue\": \"\",\n",
    "                \"in\": {\n",
    "                    \"$concat\": [\n",
    "                        {\"$cond\": [\n",
    "                            {\"$eq\": [\"$$value\", \"\"]},\n",
    "                            \"\",\n",
    "                            \"\"\n",
    "                        ]},\n",
    "                        \"$$this\"\n",
    "                    ]\n",
    "                }\n",
    "            }},\n",
    "            \"review_score_value\": \"$review_score.review_scores_value\",\n",
    "            \"price\": \"$price\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$amenities_str\",  # Group by the joined amenities string\n",
    "            \"avg_review_score_value\": {\"$avg\": \"$review_score_value\"},\n",
    "            \"sum_price\": {\"$sum\": \"$price\"}\n",
    "        }\n",
    "    }, \n",
    "    {\n",
    "        \"$sort\":{\n",
    "            \"sum_price\": -1}\n",
    "    },    \n",
    "]\n",
    "\n",
    "results = list(qa.aggregate(pipeline))\n",
    "most_expensive = results[0]['_id']\n",
    "most_expensive"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fetch the most expensive listing\n",
    "query = {\n",
    "    \"amenities\": most_expensive\n",
    "}\n",
    "list(qa.find(query).sort(\"price\", -1))\n",
    "# results"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
